{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('azul': conda)",
   "metadata": {
    "interpreter": {
     "hash": "cdcdf8de9fd7f96fd85718281ded5830c39a58369824822cfc01a5de1ee11350"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from functools import partial\n",
    "from gym.envs.toy_text import FrozenLakeEnv\n",
    "\n",
    "from mctspy.tree import (\n",
    "    DecisionNode, \n",
    "    MCTSSimulatorInterface, \n",
    "    MCTS, \n",
    "    uct_action,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenLakeMCTS(MCTSSimulatorInterface):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def step(self, state, action):\n",
    "        self.env.s = state\n",
    "        next_state, reward, *_ = self.env.step(action)\n",
    "        \n",
    "        return next_state, reward\n",
    "\n",
    "    def state_is_terminal(self, state):\n",
    "        return self.env.desc.flat[state] in (b\"G\", b\"H\")\n",
    "\n",
    "    def enumerate_actions(self, state):\n",
    "        return set(range(self.env.action_space.n))\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rollout_value(state, env: FrozenLakeMCTS):\n",
    "    \"\"\" Rollout the environment till terminal state with random actions.\n",
    "    \"\"\"\n",
    "    cummulative_reward = 0\n",
    "    while not env.state_is_terminal(state):\n",
    "        state, reward = env.step(\n",
    "            state, \n",
    "            random.choice(tuple(env.enumerate_actions(state)))\n",
    "        )\n",
    "        cummulative_reward += reward\n",
    "\n",
    "    return cummulative_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "source": [
    "## Optimal First Action experiment\n",
    "\n",
    "Run MCTS with the budget of 1000 iterations for the first state of the 4x4 non-slippery Frozen Lake environment. Use UCB as the action selection policy and random rolout return as the state value estimator.\n",
    "\n",
    "For the starting position `1` and `2` are the optimal actions. Compute the probability of MCTS root returning optimal action.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "n_tests = 100\n",
    "n_positive = 0\n",
    "\n",
    "for _ in range(n_tests):\n",
    "    env = FrozenLakeEnv(is_slippery=False, map_name=\"4x4\")\n",
    "    env = FrozenLakeMCTS(env)\n",
    "\n",
    "    mcts = MCTS(env, uct_action, partial(random_rollout_value, env=env), 1000)\n",
    "    mcts_root = DecisionNode(env.get_initial_state(), 0, 0, {})\n",
    "\n",
    "    # Build tree\n",
    "    mcts.build_tree(mcts_root)\n",
    "\n",
    "    # Get the best score in root Node\n",
    "    best_score = max(chance_node.value / chance_node.visits for chance_node in mcts_root.children.values())\n",
    "\n",
    "    # Compute scores for two optimal actions\n",
    "    a1_score = mcts_root.children[1].value / mcts_root.children[1].visits\n",
    "    a2_score = mcts_root.children[2].value / mcts_root.children[2].visits\n",
    "\n",
    "    if a1_score == best_score or a2_score == best_score:\n",
    "        n_positive += 1\n",
    "\n",
    "n_positive / n_tests"
   ]
  },
  {
   "source": [
    "## Shortest Path Experiment\n",
    "\n",
    "Ues MCTS with the budget of 1000 iterations as the policy to rollout the 4x4 non-slippery Frozen Lake environment. UCB is the action selection policy and random rolout return is the state value estimator.\n",
    "\n",
    "Compute the probablity of MCTS finding the shortest path from the start to goal state."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "n_tests = 100\n",
    "n_positive = 0\n",
    "\n",
    "for _ in range(n_tests):\n",
    "\n",
    "    env = FrozenLakeEnv(is_slippery=False, map_name=\"4x4\")\n",
    "    env = FrozenLakeMCTS(env)\n",
    "\n",
    "    state = env.get_initial_state()\n",
    "    trajectory = [state]\n",
    "\n",
    "    mcts = MCTS(env, uct_action, partial(random_rollout_value, env=env), 1000)\n",
    "    mcts_root = DecisionNode(state, 0, 0, {})\n",
    "    \n",
    "    current = mcts_root\n",
    "\n",
    "    while not env.state_is_terminal(state):\n",
    "        # Compute the tree for the current node\n",
    "        mcts.build_tree(current)\n",
    "\n",
    "        # Select the best chance node according to UCB with 0 ecxploration\n",
    "        action = uct_action(current, 0)\n",
    "        state, reward = env.step(state, action)\n",
    "\n",
    "        # Warm-start the MCTS tree for the next iteration\n",
    "        current = current.children[action].children[state]\n",
    "        \n",
    "        trajectory.append(state)\n",
    "\n",
    "    if len(trajectory) == 7:\n",
    "        n_positive += 1\n",
    "\n",
    "n_positive / n_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}